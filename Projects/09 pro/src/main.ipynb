{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "931ec577",
   "metadata": {},
   "source": [
    "## K-Means Clustering Algorithm\n",
    "\n",
    "**K-Means** is one of the most widely used algorithms in machine learning, particularly in **unsupervised learning**. The goal of K-Means is to partition the dataset into $K$ distinct, non-overlapping clusters, where each cluster is represented by its center (centroid).\n",
    "\n",
    "\n",
    "\n",
    "### Steps of the K-Means Algorithm:\n",
    "\n",
    "1. **Initialization**: Randomly select $K$ data points as the initial cluster centroids.\n",
    "2. **Assignment**: Assign each data point to the nearest centroid using Euclidean distance.\n",
    "3. **Update**: Compute new centroids as the mean of the data points assigned to each cluster.\n",
    "4. **Repeat** steps 2 and 3 until the centroids no longer change significantly (or for a fixed number of iterations).\n",
    "\n",
    "\n",
    "\n",
    "### Objective Function:\n",
    "\n",
    "The K-Means algorithm aims to minimize the total within-cluster variance, which is calculated as:\n",
    "\n",
    "$$\n",
    "J = \\sum_{i=1}^{K} \\sum_{x \\in C_i} \\| x - \\mu_i \\|^2\n",
    "$$\n",
    "\n",
    "- $C_i$: the $i$-th cluster  \n",
    "- $\\mu_i$: the centroid of cluster $i$  \n",
    "- $\\| x - \\mu_i \\|^2$: the squared Euclidean distance between point $x$ and its cluster centroid\n",
    "\n",
    "\n",
    "\n",
    "### Advantages:\n",
    "- Simple and fast\n",
    "- Easy to understand and implement\n",
    "\n",
    "### Disadvantages:\n",
    "- Requires specifying the number of clusters $K$ in advance\n",
    "- Sensitive to initial centroid selection\n",
    "- Sensitive to outliers\n",
    "- Works best for spherical-shaped clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eac72f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
